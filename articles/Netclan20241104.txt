Data integration big data performance using Elasticsearch Client Background Client : Industry Type : Services : Organization Size : Project Objective Project Description Solution Project Deliverables Tools used Language/techniques used Skills used Databases used Web Cloud Servers used technical Challenges Faced Project Execution Technical Challenges Solved Business Impact Project Snapshots Blackcoffer Insights Blackcoffer Insights Client : Leading Tech Firm USA Industry Type : & Consulting Services : Software , Business Solutions , Consulting Organization Size:200+ Migrate existing databases Postgres elastic search since Elasticserach performs better search operations . addition , backend javascript also needed changed order query new elasticsearch database . client ’ website visualization tool . also GUI add filters . make visualizations , least 50,000 records needed pulled Postgres database whose size would around 200mbs . would take lot time ( nearly 20-30 secs ) . Adding filters would take additional time . task move entire database Elasticsearch postgres since way faster search operations also filtering data . Since database changed , also write new backend code would query Elasticsearch database . Elasticsearch Postman Kibana Logstash Python Javascript Amazon Web Services Postgres Docker Git Bucket Github Javascript Json Domain-Specific Language elasticsearch bash Elasticsearch query knowledge Postgres query knowledge Networking Javascript Backend web stack Postgres Elasticsearch Amazon Web Services ( AWS ) solve mentioned problem , used gzip request url ’ header . significantly reduced execution times . Earlier postgres infrastructure took around 20-30 secs consistently less 10 secs perform filter search operations . would contribute better user experience . Search LATEST INSIGHT ARTICLES Archives Categories Tags Neve| Powered byWordPress Neve| Powered byWordPress