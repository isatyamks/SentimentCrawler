Stocktwits Data Structurization Client Background Client : Industry Type : Services : Organization Size : Project Objective Project Description Solution Project Deliverables Tools used Language/techniques used Models used Skills used Databases used Web Cloud Servers used technical Challenges Faced Project Execution Technical Challenges Solved Project Snapshots Figure 1 Sample Input Dataframe Converting Outer JSON Figure 2 Sample Output Dataframe Solving Nested JSON Data Preprocessing Blackcoffer Insights Blackcoffer Insights Client : leading financial institution USA Industry Type : Financial services & Consulting Services : Financial consultant Organization Size:100+ > process two json file stocktwits_legacy_msg_2015_10.txt ( file size = 2 GB ) & stocktwits_legacy_msg_2015_10.txt ( file size = 3.5 GB ) . > handle Nested Json files conversion one merged Data Frame need perform Data Structurization . > accessing Json file JupyterNB , need perform Chunking file size bigger json format avoid PC standstill . > Data Preprocessing need perform Exploratory Data Analysis Data . > Conditional Programming deal Data Transferring particular folder based column values . training period involved 2 live projects , One project named ‘ Stocktwits Data Structurization ’ process huge JSON Data already obtained size data nearly 5 GB need process data chunking chunk size = 20000 rows time . file nested JSON data within ’ attributes abstracts data nested columns new dataframe . Completed handling complex nested json formed columns abstracted nested json . need Handle missing data mapping another index dataset missing values certain attributes handled mean value 0 substitution . task involves numerous pandas operations along multiple python functions . done Exploratory Data Analysis cleaned dataset finding correlation matrix plotting certain seaborn graphs strong correlated attributes . Worked Accessing Json Data , done tree Analysis Json Sample data . File big reading applying Python Code JupyterNb , performed chunking stocktwits_legacy_messages_2015_10.txt chunk size = 20000 rows time . Similarly trying file . Created list chunked files Json Data & Concat files list . File Nested Json data within ’ attributes abstracted data nested columns new DataFrame . Completed handling complex nested json formed columns abstracted nested json . Renamed columns identification . ( Eg : ‘ id ’ ‘ entities_id ’ ) likewise others . merging data ’ create issue . Completed forming Preprocessed csv file 1st json file Output2015.csv . Second file size > 3gb splitted file ten parts individually solved nested json parts like done 1st file finally concat one , handled columns arrangements removed unwanted columns finally removed dictionary representation entity_sentiments column . Completed forming Preprocessed csv file 2nd json file Output_Stocktwits_2017.csv . cleaned dataset finding correlation matrix plotting certain seaborn graphs strong correlated attributes . done Exploratory Data Analysis cleaned dataset finding correlation matrix plotting certain seaborn graphs strong correlated attributes . Conditional Programming deal Data Transferring particular folder based column values . ● Jupyter Notebook ● Anaconda ● Notepad++ ● Sublime Text ● Brackets ● JsonViewer ● Python Programming project ‘ Stocktwits Data Structurization ’ developed software model makes project high quality , reliable cost effective . ● Software Model : RAD ( Rapid Application Development model ) Model ● project follows RAD Model model forming loop end start , also project based prototyping without specific planning . RAD model , less attention paid planning priority given development tasks . targets developing software short span time . ● Advantages RAD Model : Changing requirements accommodated . Progress measured . Iteration time short use powerful RAD tools . Productivity fewer people short time . Reduced development time . Increases reusability components . Quick initial reviews occur . Encourages customer feedback . Integration beginning solves lot integration issues ● Data Mining ● Data Wrangling ● Data Visualization ● Python Programming including OOPs Exception Handling Databases used , data stored Google Drive Local Device . Cloud Server used ● Handling Huge Data Data Cleaning ● JSON Data Serialization . ● Solving Complex Nested JSON among data provided . ● Handling Huge Data Data Cleaning Solved Breaking Dataset 10 stream parts data huge able read easily Jupyter NB . ● JSON Data Serialization Solved Data Chunking chunk_size=20000 means serialization data processing 20000 rows time . ● Solving Complex Nested JSON among data provided . Viewed Structure part data JSON Viewer Changed data proper standard JSON Format . Reading JSON Data Performing Normalization Nested JSON data setting maximum level normalization specifying proper orient form . Normalization remaining Unsolved Nested JSON solved using Dictionary Conversions Structuring data . Figure 1 Sample Input Dataframe Converting Outer JSON Figure 2 Sample Output Dataframe Solving Nested JSON Data Preprocessing Search LATEST INSIGHT ARTICLES Archives Categories Tags Neve| Powered byWordPress Neve| Powered byWordPress